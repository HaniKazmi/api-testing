\chapter{Background}

\section{State of the Internet}
In 1989, Tim Berners-Lee proposed a communication system for CERN\cite{informationproposal}. He soon realized the concept could be expanded, and in 1990 he published the proposal for what would become the World Wide Web\cite{wwwproposol}. The document suggested using 'hypertext'\footnote{Structured text that uses links between nodes containing text.} "to link and access information of various kinds as a web of nodes in which the user can browse at will". HTTP was defined as a protocol to exchange hypertext between devices\cite{rfc2616}, and has been the basis of the World Wide Web ever since.

However, while the HTTP standard has remained constant, the web has been continuously evolving over the past decade. Berners-Lee envisioned web pages consisting of static data and hyper-links\footnote{A reference to data on a web document.} to other web pages. This was originally the case, with web sites consisting of text and images, coded using HTML and JavaScript. As the computing power available to general users increased, more dynamic sites started appearing following the client-server model\footnote{The server serving web pages generates custom HTML documents on the fly, and sends them to the client web browser.} to allow more user content and interaction\footnote{Coined 'Web 2.0'.}. Web Browser developers also released new, faster, JavaScript engines\footnote{Browser JavaScript Performance in 2008: \url{http://www.cnet.com/news/speed-test-google-chrome-beats-firefox-ie-safari/}}\footnote{Browser JavaScript Performance in 2010: \url{http://www.pcgameshardware.com/aid,687738/Big-browser-comparison-test-Internet-Explorer-vs-Firefox-Opera-Safari-and-Chrome-Update-Firefox-35-Final/Reviews/}} which allowed even more interactive web pages. Of particular note was the rise of AJAX\footnote{Asynchronous JavaScript and XML: A group of web techniques that allow data to be send to and received from a server asynchronously, thus allowing parts of web pages to be updated without having to fetch an entire new page.}, which allowed websites to transition from page based documents to single page 'web apps'.

\subsection{The HTTP Protocol}
HTTP/1.1 is currently the most widely used protocol for data communications on the Internet\footnote{HTTP/2 is currently under development but has not yet been finalised.}. HTTP functions as a request-response protocol: A client submits an HTTP request to a server, which returns resource as a response. The HTTP/1.1 specification defines 9 types of requests\footnote{Referred to as 'verbs'.}:
\begin{center}
\begin{tabular}{c | p{10cm}}
\textbf{Verb} & \textbf{Description} \\ \hline
GET & Requests a representation of the specified resource. \\
HEAD & Asks for the response identical to the one that would correspond to a GET request, but without the response body. \\
POST & Asks the server to add the enclosed entity as a subordinate to the specified resource. \\
PUT & Asks the server to add the enclosed entity to the specified resource. \\
DELETE & Deletes the specified resource. \\
PATCH & Partially modification to a resource. \\
TRACE & Echoes back the received request so that a client can see what (if any) changes or additions have been made by intermediate servers.\\
OPTIONS & Returns the HTTP methods that the server supports for the specified URL\\
CONNECT & Converts the request connection to a transparent TCP/IP tunnel, generally used for SSL-encrypted communication.\\
\end{tabular}
\end{center}
These requests are ubiquitously implemented in major web browsers and servers, allowing for a standardised way to build web apps.

\subsection{Web APIs}
Web APIs are built upon HTTP, and are used for many purposes around the Internet. One of the more common ones is to allow the front-end of a web app to communicate with the server, and fetch dynamic content. While there are no official standards for web APIs, there are two common architecture styles used when designing them.

\subsubsection{SOAP}
Originally an acronym for Simple Object Access protocol, SOAP\cite{soap12} is a protocol specification regularly used for APIs. It is based on XML, and consists of three parts:

\begin{enumerate}
\item An envelope which defines the message structure and how to process it.
\item Rules for encoding data types.
\item Convention for representing procedure calls and responses.
\end{enumerate}

\noindent
A SOAP message is an XML document consisting of:

\begin{center}
\begin{tabular}{c| p{10cm}}
\textbf{Element} & \textbf{Description} \\ \hline
Envelope & Identifies the document as a SOAP message. \\
Header & Contains header information. \\
Body & Contains the call and response information. \\
Fault & Contains information about any errors that occurred. \\
\end{tabular}
\end{center}
\noindent 

SOAP's main strengths lie in security (due to supporting SSL encryption) and reliability (any errors are documented in the Fault packet). However, due to the complex structures required for a SOAP API to function, it is generally not used outside of enterprise applications.

\begin{code}
\begin{lstlisting}[frame=lines]{XML}
POST /InStock HTTP/1.1
Host: www.example.org
Content-Type: application/soap+xml; charset=utf-8
Content-Length: 299
SOAPAction: "http://www.w3.org/2003/05/soap-envelope"
 
<?xml version="1.0"?>
<soap:Envelope xmlns:soap="http://www.w3.org/2003/05/soap-envelope">
  <soap:Header>
  </soap:Header>
  <soap:Body>
    <m:GetStockPrice xmlns:m="http://www.example.org/stock">
      <m:StockName>IBM</m:StockName>
    </m:GetStockPrice>
  </soap:Body>
</soap:Envelope>
\end{lstlisting}
\caption{Example SOAP message}
\end{code}

\subsubsection{Representational State Transfer}
Representational State Transfer(REST) is a software architecture style based on a series of guidelines for creating scalable web services\cite{rest}. The formal REST constraints are:  

\begin{center}
\begin{tabular}{| c | p{10cm} |}
\hline
\textbf{Constraint} & \textbf{Description} \\ \hline
Client-server & An interface separates the client and server, allowing separation of concern and more portable code. \\ \hline
Stateless & No client context is stored on the server; each request contains all the information required to service it. \\ \hline
Cacheable & Responses must define whether they are cacheable. \\ \hline
Layered System & A client can not tell what is servicing the request; there may be intermediaries to improve scalability.\\ \hline
Code on Demand & (Optional) Servers can transfer executable code to the client to extend or modify functionality.\\ \hline
Uniform Interface
& \textbf{Uniform Interface:} Individual resources are identified in the request. Furthermore, the resource internal representation may be separate from the representation returned to the client. \\ \cline{2-2}
& \textbf{Manipulation of resources through these representations:} If a client has a representation of a resource, it can modify or delete it. \\ \cline{2-2}
& \textbf{Self-descriptive messages}: Each message includes information about how to process it. \\ \cline{2-2}
& \textbf{Hypermedia as the engine of application state}: Clients may only transition through actions defined by hypermedia on the server, with the one exception being a externally defined entry point. \\ \hline
\end{tabular}
\end{center}

When a web api conforms to these constraints, it is known as a 'restful api'. If the api is HTTP based, as well be explored in this report, it has the following properties:
\begin{enumerate}
	\setlength{\itemsep}{0pt}
	\item Base URL, eg \url{http://example.com/resources/}
	\item An Internet Media Type\footnote{A standard identifier on the Internet to define the type of data in a file.}\cite{internetmedia} for the data, usually JSON or XML.
	\item Based upon standard HTTP verbs
	\item Hypertext links to reference state
	\item Hypertext links to reference related sources.
\end{enumerate}

Restful apis consist of two types of endpoints: collections, which return links to multiple resources(which may be collections themselves), or elements, which return the representation of a single resource.

\begin{tabularx}{\textwidth}{| l *{2}{|X}|}
\multicolumn{3}{c}{Example restful api methods} \\ \hline
\textbf{Resource} & Collection \linebreak \url{http://example.com/resources/} & Element \linebreak \url{http://example.com/resources/item42} \\ \hline
\vtop{\hbox{\strut \textbf{GET}}\hbox{\strut (nullipotent)}} & List the URIs with optionally other details of the collection's members. & Retrieve a representation of the element in an appropriate Internet media type. \\ \hline
\vtop{\hbox{\strut \textbf{PUT}}\hbox{\strut (idempotent)}} & Replace the entire collection with another collection. & Replace the referenced element. Create it if it does not exist. \\ \hline
\textbf{POST} & Add a new element to the collection. The new entry's URI is automatically assigned and is usually returned & Not widely used, treats the element as a collection to create an entity in it. \\ \hline
\vtop{\hbox{\strut \textbf{DELETE}}\hbox{\strut (idempotent)}} & Delete the entire collection. &  Delete the referenced element. \\ \hline
\end{tabularx}

Restful APIs are very common in modern web apps due to being self documenting\footnote{Due to states being encoded in the hypermedia, restful apis can be navigated with no external documentation.} and easily scalable.

\subsubsection{Summary}

WHile both SOAP and restful web apis are common on the Internet, this report will limit itself to considering only those constrained by the rest architecture. This is due to SOAP apis generally being very complex structures, and difficult to automatically parse by a computer. By contrast, due to the 'hypermedia as the engine of application state' constraint, web apis can be automatically by crawled and documented from the entry point. 

The Livedrive api 'Onyx' is fully restful, thereby allowing it to serve as a case study.



\section{API Documentation}

As discussed earlier, restful apis are self documenting in that each endpoint contains references to its entities. However this does not provide full detail on how the api works, and what format data will be returned in. Therefore, there are multiple standards in the industry to accomplish this, which can broadly be split into two categories.

\subsection{Human documentation}

High level overview of how the api works, this is usually written for and intended for humans.

\begin{figure}[ht]

\textbf{Arguments}

This method has the URL \url{https://slack.com/api/api.test} and follows the Slack Web API calling conventions.

\begin{tabularx}{\textwidth}{c|X|c|X}
\textbf{Argument} & \textbf{Example} & \textbf{Required} & \textbf{Description} \\ \hline
error & myerror & optional & Error response to return \\
foo & bar & Optional & example property to return \\
\end{tabularx}


\textbf{Response}

The response includes any supplied argument

\begin{code}
\begin{minted}[frame=lines]{js}
{
    "ok": true,
    "args": {
        "foo": "bar"
    }
}
\end{minted}
\end{code}

If called with an error argument an error response is returned:

\begin{code}
\begin{minted}[frame=lines]{js}
{
    "ok": false,
    "error": "myerror",
    "args": {
        "error": "myerror"
    }
}
\end{minted}
\end{code}
\caption{Example high level documentation}
\end{figure}

While useful for humans, this type of documentation can not be parsed easily and so will not be used in this report.

\subsection{Specifications}

More rigid and formally defined, API specifications can be read by both humans and machines. While specifications can be written on a ad-hoc basic, there are several popular languages in use for defining them. Unfortunately, there is no industry standard, and any organisation may use any method of documentation they so choose.

\subsubsection{RAML}

RESTful API Modeling Language (RAML)\cite{ramlwebsite} is a specification language for restful apis, based upon YAML\footnote{YAML Ain't Markup Language: a human-readable data serialization format.}\cite{yamlspec}. Due to being based upon YAML, it is both human readable, and fairly easily parsed by a machine due to mature open source YAML parsers. The RAML group provides multiple tools to make working with RAML easier for the end user, however it is still a young project and some major expected functionality such as reference parsers are still missing.

\begin{code}
\begin{minted}[frame=lines]{YAML}
#%RAML 0.8
 
title: World Music API
baseUri: http://example.api.com/{version}
version: v1
traits:
  - paged:
      queryParameters:
        pages:
          description: The number of pages to return
          type: number
  - secured: !include http://raml-example.com/secured.yml
/songs:
  is: [ paged, secured ]
  get:
    queryParameters:
      genre:
        description: filter the songs by genre
  post:
  /{songId}:
    get:
      responses:
        200:
          body:
            application/json:
              schema: |
                { "$schema": "http://json-schema.org/schema",
                  "type": "object",
                  "description": "A canonical song",
                  "properties": {
                    "title":  { "type": "string" },
                    "artist": { "type": "string" }
                  },
                  "required": [ "title", "artist" ]
                }
            application/xml:
    delete:
      description: |
        This method will *delete* an **individual so
\end{minted}
\caption{Example RAML specification}
\label{lst:my_func}
\end{code}

RAML contains many abstraction techniques such as trait definitions to allow similar endpoints to be factored out. It also allows multiple Internet media types to be defined as responses in-line, allowing for a great deal of flexibility. However, due to all these abstractions, creating a full parser is difficult.

\subsubsection{API Blueprint}

Created by Apiary, API Blueprint\cite{blueprintsite} is a specification language based upon Markdown. Similar to RAML, it is fairly new, however it has a large set of usable tooling. Being closed source, the specification can not be easily expanded and therefore is deeply tied into the existing tool set. It also does not include the abstraction tools of RAML, thereby resulting in many repeated definitions in a specification.

However, the tooling contains many useful utilities for automatic testing such as automatic mock server generation, thereby making it a popular choice in the industry.

\subsubsection{Swagger}

Swagger\cite{swaggersite} is the last of the major api specification languages. It is based upon JSON, and while it is human readable it is more aimed at machine processing. It is the most mature of the three languages discussed so far. However, the aim of Swagger is code generation and server integrations: it is not designed to be used for unit testing. It consists of an initial specification written in JSON, which can then be transformed into a HTML site, a YAML representation, as well as processed by a variety of third party tools.



\section{Unit Testing}

Unit testing is the simplest technique used when creating web apis: it consists of writing a test based upon the api specification to test a specific feature of an endpoint, and then implementing the api until it passes. Due to the wide variety of api specifications, along with the range of requirements that need to be tested, this is generally done manually by the engineer working on the endpoint. Unit tests have the further advantage of alerting the engieer if the functionality ever breaks due to future engineering. Unit tests are organised in a suite which can be run upon the code base without affecting any deployed versions of the application.


\begin{figure}[ht]
\begin{tikzpicture}[node distance=3cm, framed]
\node (start) [process] {Write a unit test};
\node (in1)[align=center] [decision, below right of=start, yshift=-0.5cm] {Check if the \\test fails};
\node (in2)[align=center] [process, below right of = in1] {Write production \\ code};
\node (in3)[align=center] [decision, below right of = in2] {Run all tests};
\node (in4)[align=center] [process, below right of = in3] {Clean up code};

\draw [arrow] (start) |- (in1);
\draw [arrow] (in1) |- node[anchor=west, align=center] {test \\succeeds} (start);
\draw [arrow] (in1) |- node[anchor=east, align=center] {test \\fails} (in2);
\draw [arrow] (in2) |- (in1);
\draw [arrow] (in2) |- (in3);
\draw [arrow] (in3) |- node[anchor=west, align=center] {test \\fails} (in2);
\draw [arrow] (in3) |- node[anchor=east, align=center] {test \\succeeds}(in4);
\draw [arrow] (in4) |- (in3);
\draw [arrow] (in4.east) -- ++(0.5,0) node(lowerright){}  |- node[anchor=south] {Repeat} ($(start.north)+(0,0.5)$) -- (start.north);
\end{tikzpicture}
\caption{The Test-Driven Development cycle}
\end{figure}


Unit Testing is generally synonymous with Test-Driven Development (TDD), where all tests are written before the api implementation begins. The tests are written based upon the api specification, thereby allowing any gaps in the specification to be discovered and filled in early. It also leads to less buggy software if done properly, as every module is sure to be unit tested. There are many tools to aid in trying to automate part of this process, some of which are discussed below.

\subsection{FitNesse}

FitNesse\footnote{\url{http://www.fitnesse.org}} is an acceptance testing framework\footnote{Unit tests written for the specific purpose of ensuring that the specification is fully implemented.}. It allows users to input formatted test cases, which it uses to automatically generates tests and execute them against the web api. While it generally works well when setup, it requires the creation of fixtures\footnote{Support classes with the api framework to allow the tests to run} which may be difficult depending on how the api is implemented. The test cases are created in a wiki using a natural language markup, which allows non-technical members of the team to also contribute to it.

FitNesse acts like a black-box test engine: the tester writing FitNesse inputs should not be aware how the specification is implemented. While a good idea in theory, there are usually bugs introduced due to the fixtures which can cause the acceptance tests to fail.  Furthermore, FitNesse is a completely self contained platform: it does not integrate with any other service, limiting furthermore automation.

\subsection{RSpec}

RSpec\footnote{\url{http://rspec.info}} is an acceptance testing framework for Ruby. It allows 'behaviours' to be defined which emulate a human using the api, and then automatically run against the code-base. It is by far the most commonly used testing framework for ruby apis, however it has seen limited use in other languages. Tests are written in a DSL based upon ruby which mimics natural language, making it easy to quickly add new tests as the need arises. Like FitNesse, RSpec is completely self contained and can not integrate with other services: the specification must be manually converted into behaviors.

\subsection{xUnit}

xUnit is a family of unit testing frameworks for object-oriented languages. They consist of seven major components:

\begin{tabular}{c  p{10cm}}
\textbf{Test runner} & Runs tests implemented using xUnit \\
\textbf{Test case} & Base class tests inherit from \\
\textbf{Test fixture} & Sets up the environment for a test. \\
\textbf{Test suite} & A set of tests that depend on the same fixture. \\
\textbf{Test execution} & Tests run an initializer, then the body of the test, and finish by cleaning up any changes they made. \\
\textbf{Test result formatter} & Interprets the results from the runner in a human readable format. \\
\textbf{Assertions} & A logical condition used to evaluate whether a test passed or failed. \\
\end{tabular}

xUnit frameworks are generally open source. This has allowed an ecosystem of services to develop around them, leading to easy integration of third party services. It is in active use by a wide variety of organizations, such as Microsoft\footnote{\url{http://www.nunit.org}} and Oracle\footnote{\url{http://junit.org}}. It is considered the industry standard in most enterprise application.

While powerful, xUnit frameworks again require the specification to be transformed into a propriety format. It can be very involved to setup, as fixtures need to be created for every test suite.


\subsection{Summary}

While there are a wast array of automatic testing tools, all of them require a large amount of manual intervention. Namely, all the tools discussed above require the original specification to be transformed into propriety formats. While this would not be an issue if this were to happen one, api specifications are continuously updated and so require an inordinate effort by the software engineer to keep the two models in sync. Furthermore, this is a likelihood of introducing errors when converting the specification to test cases.

An ideal solution would be able to parse a standardized specification and automatically generate all the relevant test cases, then execute the test cases against the code base. It would then be able to output which test cases failed in a human readable format.


\section{Livedrive}

Due to large possible scope of this project due to the myriad apis in production, I will limit the scope to an api provided by the organization Livedrive. Livedrive plan on using the completed project in production. They have begun created a new web api, code named 'Onyx', which can act as a good case study on how well the project will work in real world use cases.

Livedrive is a cloud backup company. They provide consumer facing clients which can be used to manage files. These files are then sent to an off-site server for storage, thereby allowing access from other clients and protecting them from machine failure. Onyx will be used to communicate between the clients and backend servers, allowing actions such as 'rename' and 'delete'. Onyx' is written in C\#, and is currently tested using FitNesse. Due to the quickly evolving nature of the api, FitNesse has proved too slow to be scalabe in the long term.

As Onyx is a trade secret, no code directly from the project will appear in the report. Instead, I will construct a mock api replicating the features of Onyx necessary to implement this project, as needed. This mock will aim to provide the same responses as Onyx, but will be merely imitating the responses.